{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle & Huggingface, very important for showcasing your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# ! KEY CODE\n",
    "from datasets import load_dataset, get_dataset_split_names\n",
    "import datasets as huggingface_datasets\n",
    "\n",
    "training_dataset = load_dataset(\"ajinkyakolhe112/imagenet_10c_tiny\", split=\"train\")\n",
    "# dataset = load_dataset(\"imagenet-1k\")\n",
    "# get_dataset_split_names(\"imagenet-1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision, torch\n",
    "transformations_list = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.PILToTensor(),\n",
    "        torchvision.transforms.Resize((256,256))\n",
    "    ])\n",
    "\n",
    "def transform_datasets(examples):\n",
    "    \"\"\"\n",
    "        PSEUDO-CODE: `examples['image'] = transforms_list( examples['image'] )`\n",
    "    \"\"\"\n",
    "    assert examples['image'].__len__() == examples['label'].__len__()\n",
    "    examples['image_tensor']   = []\n",
    "    for image in examples['image']:\n",
    "        transformed_image = transformations_list(image)\n",
    "        transformed_image = transformed_image.to(torch.float32)\n",
    "        examples['image_tensor'].append(transformed_image)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "training_dataset.set_transform(transform_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pytorch Dataset -> Data Loader\n",
    "BATCH_SIZE = 10\n",
    "TOTAL_BATCHES = len(training_dataset) / BATCH_SIZE\n",
    "training_dataloader   = torch.utils.data.DataLoader( training_dataset  , batch_size= BATCH_SIZE, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape     Output Shape    Kernel Shape    Param #         Trainable       Param %\n",
      "==================================================================================================================================\n",
      "Sequential                               [3, 224, 224]   [256, 6, 6]     --              --              True                 --\n",
      "├─Conv2d: 1-1                            [3, 224, 224]   [64, 55, 55]    [11, 11]        23,296          True              0.94%\n",
      "│    └─weight                                                            [3, 64, 11, 11] ├─23,232\n",
      "│    └─bias                                                              [64]            └─64\n",
      "├─ReLU: 1-2                              [64, 55, 55]    [64, 55, 55]    --              --              --                   --\n",
      "├─MaxPool2d: 1-3                         [64, 55, 55]    [64, 27, 27]    3               --              --                   --\n",
      "├─Conv2d: 1-4                            [64, 27, 27]    [192, 27, 27]   [5, 5]          307,392         True             12.45%\n",
      "│    └─weight                                                            [64, 192, 5, 5] ├─307,200\n",
      "│    └─bias                                                              [192]           └─192\n",
      "├─ReLU: 1-5                              [192, 27, 27]   [192, 27, 27]   --              --              --                   --\n",
      "├─MaxPool2d: 1-6                         [192, 27, 27]   [192, 13, 13]   3               --              --                   --\n",
      "├─Conv2d: 1-7                            [192, 13, 13]   [384, 13, 13]   [3, 3]          663,936         True             26.88%\n",
      "│    └─weight                                                            [192, 384, 3, 3] ├─663,552\n",
      "│    └─bias                                                              [384]           └─384\n",
      "├─ReLU: 1-8                              [384, 13, 13]   [384, 13, 13]   --              --              --                   --\n",
      "├─Conv2d: 1-9                            [384, 13, 13]   [256, 13, 13]   [3, 3]          884,992         True             35.83%\n",
      "│    └─weight                                                            [384, 256, 3, 3] ├─884,736\n",
      "│    └─bias                                                              [256]           └─256\n",
      "├─ReLU: 1-10                             [256, 13, 13]   [256, 13, 13]   --              --              --                   --\n",
      "├─Conv2d: 1-11                           [256, 13, 13]   [256, 13, 13]   [3, 3]          590,080         True             23.89%\n",
      "│    └─weight                                                            [256, 256, 3, 3] ├─589,824\n",
      "│    └─bias                                                              [256]           └─256\n",
      "├─ReLU: 1-12                             [256, 13, 13]   [256, 13, 13]   --              --              --                   --\n",
      "├─MaxPool2d: 1-13                        [256, 13, 13]   [256, 6, 6]     3               --              --                   --\n",
      "==================================================================================================================================\n",
      "Total params: 2,469,696\n",
      "Trainable params: 2,469,696\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 9.90\n",
      "==================================================================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 3.88\n",
      "Params size (MB): 9.88\n",
      "Estimated Total Size (MB): 14.36\n",
      "==================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential( \n",
    "            # 5 Convolution Layers...Architecture [(neurons, kernel_size): (64,11), (192,5), (384,3), (256,3), (256,3), ]\n",
    "            # LAYER NO 1\n",
    "            nn.Conv2d(3, 64, kernel_size=(11,11), stride= 4, padding= 2),\n",
    "            nn.ReLU(inplace=True), # Decision on, which 50% to ignore... \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            # LAYER NO 2\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            # LAYER NO 3\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # LAYER NO 4\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # LAYER NO 5\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "features = nn.Sequential( \n",
    "    # 5 Convolution Layers...Architecture [(neurons, kernel_size): (64,11), (192,5), (384,3), (256,3), (256,3), ]\n",
    "    # LAYER NO 1\n",
    "    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(11,11), stride= 4, padding= 2),\n",
    "    nn.ReLU(inplace=True), # Decision on, which 50% to ignore... \n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "    # LAYER NO 2\n",
    "    nn.Conv2d(in_channels=64, out_channels=192, kernel_size=(5,5), padding=2),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "    # LAYER NO 3\n",
    "    nn.Conv2d(in_channels=192, out_channels=384, kernel_size=(3,3), padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    # LAYER NO 4\n",
    "    nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3), padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    # LAYER NO 5\n",
    "    nn.Conv2d(in_channels=256, out_channels= 256, kernel_size=(3,3), padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    ")\n",
    "from torchinfo import summary\n",
    "summary(features, input_size=(3,224,224), \n",
    "        verbose=2, col_names = [\"input_size\", \"output_size\",\"kernel_size\", \"num_params\",\"trainable\", \"params_percent\"], col_width=15);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
      "             ReLU-10        [-1, 128, 112, 112]               0\n",
      "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
      "             ReLU-13        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
      "             ReLU-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
      "             ReLU-20          [-1, 256, 56, 56]               0\n",
      "           Conv2d-21          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
      "             ReLU-23          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-24          [-1, 256, 28, 28]               0\n",
      "           Conv2d-25          [-1, 512, 28, 28]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-27          [-1, 512, 28, 28]               0\n",
      "           Conv2d-28          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-30          [-1, 512, 28, 28]               0\n",
      "           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-33          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-34          [-1, 512, 14, 14]               0\n",
      "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-36          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-37          [-1, 512, 14, 14]               0\n",
      "           Conv2d-38          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-39          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-40          [-1, 512, 14, 14]               0\n",
      "           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-43          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-44            [-1, 512, 7, 7]               0\n",
      "          Dropout-45                [-1, 25088]               0\n",
      "           Linear-46                 [-1, 4096]     102,764,544\n",
      "             ReLU-47                 [-1, 4096]               0\n",
      "          Dropout-48                 [-1, 4096]               0\n",
      "           Linear-49                 [-1, 4096]      16,781,312\n",
      "             ReLU-50                 [-1, 4096]               0\n",
      "           Linear-51                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 134,309,962\n",
      "Trainable params: 134,309,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 322.10\n",
      "Params size (MB): 512.35\n",
      "Estimated Total Size (MB): 835.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(7*7*512, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(VGG16(), input_size=(3,224,224));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_images = 1,28,28. output = (1,1)\n",
    "layer = nn.Conv2d(3,1, kernel_size=(28,28)) # ONLY SEE, 28,28 pixel data... Receptive Field. RF\n",
    "\n",
    "nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3,out_channels=1,kernel_size=(15,15)), # height - (k - 1)/s = 28 - 14 = 14\n",
    "    nn.Conv2d(in_channels=3,out_channels=1,kernel_size=(15,15)), # input = 14,14. output = 1,1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build your own clean_nn module..\n",
    "\n",
    "class Linear_Layer_ajinkya API vs nn.Linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard PyTorch implementation of VGG. Pretrained imagenet model is used.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # conv1\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            \n",
    "            # conv2\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "\n",
    "            # conv3\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "\n",
    "            # conv4\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "\n",
    "            # conv5\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1000)\n",
    "        )\n",
    "\n",
    "        # We need these for MaxUnpool operation\n",
    "        self.conv_layer_indices = [0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 28]\n",
    "        self.feature_maps = OrderedDict()\n",
    "        self.pool_locs = OrderedDict()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.feature_extractor:\n",
    "            if isinstance(layer, nn.MaxPool2d):\n",
    "                x, location = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        relu = nn.ReLU()\n",
    "\n",
    "        self.branch1 = nn.Sequential(nn.Conv2d(in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0), relu)\n",
    "\n",
    "        conv3_1 = nn.Conv2d(in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        conv3_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(conv3_1, conv3_3,relu)\n",
    "\n",
    "        conv5_1 = nn.Conv2d(in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        conv5_5 = nn.Conv2d(out_channels, out_channels, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.branch3 = nn.Sequential(conv5_1,conv5_5,relu)\n",
    "\n",
    "        max_pool_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        conv_max_1 = nn.Conv2d(in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.branch4 = nn.Sequential(max_pool_1, conv_max_1,relu)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output1 = self.branch1(input)\n",
    "        output2 = self.branch2(input)\n",
    "        output3 = self.branch3(input)\n",
    "        output4 = self.branch4(input)\n",
    "        return torch.cat([output1, output2, output3, output4], dim=1)\n",
    "\n",
    "model = InceptionModule(in_channels=3,out_channels=32)\n",
    "inp = torch.rand(1,3,128,128)\n",
    "print(model(inp).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            \n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision 15 architectures\n",
    "### current **Standard** Base Models\n",
    "1. AlexNet\n",
    "2. VGG\n",
    "3. Inception V2\n",
    "4. Resnet\n",
    "5. EfficientNet\n",
    "6. SqueezeNet\n",
    "7. DenseNet\n",
    "8. Vision Transformer (ViTs)\n",
    "9. ConvNeXTs\n",
    "\n",
    "(torchvision models or huggingface timm or huggingface transformers or keras-core or kaggle models)\n",
    "\n",
    "## NLP\n",
    "### current **Standard** Base Models\n",
    "- BERT\n",
    "- GPT\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
