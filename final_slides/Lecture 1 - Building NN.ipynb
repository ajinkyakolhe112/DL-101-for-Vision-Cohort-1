{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 - Building Neural Network for Intelligence\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Section 1: Natural Intelligence = Brain\n",
    "\n",
    "#### Electrical Brain\n",
    "1. Group of Interconnected Wires (Neuron Connections) with different amount of Fat Insulation (Myelination)\n",
    "2. Carrying electrical signals (Data)\n",
    "\n",
    "#### Network Brain\n",
    "Brain is a\n",
    "1. Large \n",
    "2. Interconnected\n",
    "3. Network of\n",
    "4. Neurons\n",
    "   1. Group of Neurons at same level are called Layer\n",
    "5. Check [Brain Neural Network](http://nxxcxx.github.io/Neural-Network/)\n",
    "\n",
    "#### Single Neuron - 3 Things\n",
    "1. Input Data through Wire\n",
    "2. Wire with varying Insulation Strength via Mylenation\n",
    "3. Output Connection\n",
    "\n",
    "#### Single Neuron Diagram\n",
    "![Biological Neuron Model](https://www.researchgate.net/publication/341241129/figure/fig1/AS:888908187443205@1588943635819/Biological-Neuron-Model.ppm)\n",
    "![Single Neuron](https://media.geeksforgeeks.org/wp-content/uploads/20230410104038/Artificial-Neural-Networks.webp)\n",
    "![Layers of Neurons](https://qph.cf2.quoracdn.net/main-qimg-084ade3ed1f8a97709e374090a92e1ca.webp)\n",
    "\n",
    "#### Brain as Layered Neural Network\n",
    "![Visual Processing in Brain](https://neuwritesd.files.wordpress.com/2015/10/visual_stream_small.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Artificial Intelligence\n",
    "\n",
    "Brute Force Error Minimizer from Data\n",
    "\n",
    "```python\n",
    "\n",
    "for each x_actual & y_actual in train_data_loader:\n",
    "    y_predicted_LOGITS = model(x_actual)\n",
    "    loss               = error_func(y_predicted_LOGITS, y_actual)\n",
    "\n",
    "    dError_dWeights = torch.autograd.grad(outputs= loss, inputs = model.parameters() )\n",
    "    for weight, gradient in zip(model.parameters(), dError_dWeights):\n",
    "        weight = weight - gradient * learning_rate\n",
    "        print(weight.shape, gradient.shape)\n",
    "        print(weight, gradient)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network in Pytorch\n",
    "Neural Network has 4 Steps\n",
    "1. Data\n",
    "2. Model Architecture\n",
    "3. Model Training\n",
    "4. Model Evaluation\n",
    "\n",
    "Model Training has 5 Steps\n",
    "1. Predict from Existing Weight Values. (Network)\n",
    "2. Calculate Error of Prediction wrt y_actual\n",
    "3. Clear dError_dWeights\n",
    "4. Calculate dError_dWeights\n",
    "5. $ w = w - \\nabla * lr $\n",
    "\n",
    "$$\n",
    "\\large trained\\_model = \\operatorname*{argmin}_{\\mathbf{w}, b}\\  Loss( y_{predicted}, y_{actual})\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: wandb in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (0.15.4)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (2.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (1.26.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (67.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (4.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: torchmetrics in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (0.11.4)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (1.21.5)\n",
      "Requirement already satisfied: torch>=1.8.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: packaging in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: filelock in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (4.6.3)\n",
      "Requirement already satisfied: sympy in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.2.1)\n",
      "Requirement already satisfied: torchinfo in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (1.7.2)\n",
      "Requirement already satisfied: torchvision in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: requests in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (4.6.3)\n",
      "Requirement already satisfied: sympy in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (2.11.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch==2.0.1->torchvision) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install wandb\n",
    "!pip install torchmetrics\n",
    "!pip install torchinfo\n",
    "!pip install torchvision\n",
    "!pip install ipyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndigits_dataset = huggingface_datasets.load_dataset(\"mnist\", split=\"train\")\\ndigits_dataloader = torch.utils.data.DataLoader(digits_dataset, batch_size= 4)\\ndigits_dataset.set_format(type=\\'torch\\', format_kwargs={\"dtype\": torch.float32})\\nipyplot.plot_images(digits_dataset[\\'image\\'][0:5]);\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "import datasets as huggingface_datasets\n",
    "\n",
    "import ipyplot\n",
    "\n",
    "\"\"\"\n",
    "digits_dataset = huggingface_datasets.load_dataset(\"mnist\", split=\"train\")\n",
    "digits_dataloader = torch.utils.data.DataLoader(digits_dataset, batch_size= 4)\n",
    "digits_dataset.set_format(type='torch', format_kwargs={\"dtype\": torch.float32})\n",
    "ipyplot.plot_images(digits_dataset['image'][0:5]);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets as torchvision_datasets\n",
    "from torchvision import transforms as torchvision_transforms\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset    = torchvision_datasets.MNIST( root= '../dataset', transform= torchvision_transforms.ToTensor(), train= True, download= True )\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [0.9, 0.1])\n",
    "\n",
    "train_dataloader      = torch.utils.data.DataLoader( dataset = train_dataset,      batch_size = BATCH_SIZE, shuffle = True )\n",
    "validation_dataloader = torch.utils.data.DataLoader( dataset = validation_dataset, batch_size = BATCH_SIZE, shuffle = True )\n",
    "\n",
    "TOTAL_BATCHES = len(train_dataset) / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        #ipyplot-html-viewer-toggle-WDcvkwraAUPgjuvX3oYemd {\n",
       "            position: absolute;\n",
       "            top: -9999px;\n",
       "            left: -9999px;\n",
       "            visibility: hidden;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-label-WDcvkwraAUPgjuvX3oYemd { \n",
       "            position: relative;\n",
       "            display: inline-block;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-textarea-WDcvkwraAUPgjuvX3oYemd {\n",
       "            background: lightgrey;\n",
       "            width: 100%;\n",
       "            height: 0px;\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-WDcvkwraAUPgjuvX3oYemd:checked ~ #ipyplot-html-viewer-textarea-WDcvkwraAUPgjuvX3oYemd {\n",
       "            height: 200px;\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-WDcvkwraAUPgjuvX3oYemd:checked + #ipyplot-html-viewer-label-WDcvkwraAUPgjuvX3oYemd:after {\n",
       "            content: \"hide html\";\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            right: 0;\n",
       "            bottom: 0;\n",
       "            background: white;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <input type=\"checkbox\" id=\"ipyplot-html-viewer-toggle-WDcvkwraAUPgjuvX3oYemd\">\n",
       "        <label id=\"ipyplot-html-viewer-label-WDcvkwraAUPgjuvX3oYemd\" for=\"ipyplot-html-viewer-toggle-WDcvkwraAUPgjuvX3oYemd\">show html</label>\n",
       "        <textarea id=\"ipyplot-html-viewer-textarea-WDcvkwraAUPgjuvX3oYemd\" readonly>\n",
       "            \n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-7XBF3iyFFvrUupTEi855rR {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-7XBF3iyFFvrUupTEi855rR {\n",
       "            width: 150px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR {\n",
       "            width: 150px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR img {\n",
       "            width: 150px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-7XBF3iyFFvrUupTEi855rR]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-7XBF3iyFFvrUupTEi855rR]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-7XBF3iyFFvrUupTEi855rR]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-7XBF3iyFFvrUupTEi855rR\">\n",
       "    <div class=\"ipyplot-placeholder-div-7XBF3iyFFvrUupTEi855rR\">\n",
       "        <div id=\"ipyplot-content-div-7XBF3iyFFvrUupTEi855rR-9SYhZg9rD578S9CCkLvr4W\" class=\"ipyplot-content-div-7XBF3iyFFvrUupTEi855rR\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0UlEQVR4nGNgGJ6AN2bl/3///0dikVJJvPD379+/f/++ksSQC3v09+/fvz/n/P37XhdDcu/fr5fupYmJ/f1bjmnq3l/dDDIMDOl//4ZgSopIMjAwMOi8+vuXCybEApd8w8DAwMBgKMyw/hcOzwgf/LuKB85jQpWMtGHg+IJDI8Oivx/kccnxvvp7AJccQ8Pf5RxIXFQ7Mxl+/cAl6S7IcB2XodL3/vYzIwsg6xSTZzj7F4dG1k1/PwjgMrXs71+0iGRCZh5+h0sjg9gqzBSABwAAVxRFp5s3zwAAAAAASUVORK5CYII=\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-7XBF3iyFFvrUupTEi855rR-9SYhZg9rD578S9CCkLvr4W\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>\n",
       "        </textarea>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-7XBF3iyFFvrUupTEi855rR {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-7XBF3iyFFvrUupTEi855rR {\n",
       "            width: 150px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR {\n",
       "            width: 150px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR img {\n",
       "            width: 150px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-7XBF3iyFFvrUupTEi855rR span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-7XBF3iyFFvrUupTEi855rR]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-7XBF3iyFFvrUupTEi855rR]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-7XBF3iyFFvrUupTEi855rR]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-7XBF3iyFFvrUupTEi855rR\">\n",
       "    <div class=\"ipyplot-placeholder-div-7XBF3iyFFvrUupTEi855rR\">\n",
       "        <div id=\"ipyplot-content-div-7XBF3iyFFvrUupTEi855rR-9SYhZg9rD578S9CCkLvr4W\" class=\"ipyplot-content-div-7XBF3iyFFvrUupTEi855rR\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0UlEQVR4nGNgGJ6AN2bl/3///0dikVJJvPD379+/f/++ksSQC3v09+/fvz/n/P37XhdDcu/fr5fupYmJ/f1bjmnq3l/dDDIMDOl//4ZgSopIMjAwMOi8+vuXCybEApd8w8DAwMBgKMyw/hcOzwgf/LuKB85jQpWMtGHg+IJDI8Oivx/kccnxvvp7AJccQ8Pf5RxIXFQ7Mxl+/cAl6S7IcB2XodL3/vYzIwsg6xSTZzj7F4dG1k1/PwjgMrXs71+0iGRCZh5+h0sjg9gqzBSABwAAVxRFp5s3zwAAAAAASUVORK5CYII=\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-7XBF3iyFFvrUupTEi855rR-9SYhZg9rD578S9CCkLvr4W\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipyplot.plot_images(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=4, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "hidden_layer_1st = nn.Linear(in_features = 2, out_features = 4)\n",
    "hidden_layer_1st = nn.Linear(out_features = 4, in_features = 2)\n",
    "\n",
    "nn.Linear(out_features = 4, in_features = 2)\n",
    "nn.Linear(out_features = 8, in_features = 4)\n",
    "nn.Linear(out_features = 14, in_features = 8)\n",
    "\n",
    "layer = nn.Linear(out_features = 4, in_features = 2)\n",
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = X \\odot W + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6502, -0.4159], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight, layer.bias\n",
    "layer.weight[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_core as keras\n",
    "\n",
    "keras.layers.Dense(units = 4, activation=\"relu\")\n",
    "keras.layers.Dense(units = 8)\n",
    "keras.layers.Dense(units = 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU as ActivatePositive\n",
    "\n",
    "MODEL = nn.Sequential(\n",
    "    nn.Identity(),                                             # LAYER 1: INPUT LAYER\n",
    "    nn.Flatten(start_dim=1),                                   #          IMAGE RESHAPE\n",
    "    nn.Linear(out_features = 20, in_features = 28*28*1),       # LAYER 2: 1st Hidden Layer\n",
    "    ActivatePositive(),                                        #          Activation Function f(x) -> (if x < 0: return 0) & else (if x > 0: return x)\n",
    "    nn.Linear(out_features = 10 , in_features = 20),           # LAYER 3: Output Layer\n",
    "    # NO ACTIVATION FUNCTION ON FINAL LAYER. Called logits as pre activation value\n",
    ")\n",
    "\n",
    "model_parameters = list(MODEL.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_FUNC = nn.functional.cross_entropy\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "OPTIMIZER    = torch.optim.SGD( params= model.parameters() , lr= LEARNING_RATE)\n",
    "# GRADIENTS  = torch.autograd.grad(output = loss, input = params)\n",
    "\n",
    "model, error_func, learning_rate, optimizer = MODEL, ERROR_FUNC, LEARNING_RATE, OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape          Output Shape         Kernel Shape         Param #              Trainable            Param %\n",
      "================================================================================================================================================================\n",
      "Sequential                               [1, 28, 28]          [1, 10]              --                   --                   True                      --\n",
      "├─Identity: 1-1                          [1, 28, 28]          [1, 28, 28]          --                   --                   --                        --\n",
      "├─Flatten: 1-2                           [1, 28, 28]          [1, 784]             --                   --                   --                        --\n",
      "├─Linear: 1-3                            [1, 784]             [1, 20]              --                   15,700               True                  98.68%\n",
      "│    └─weight                                                                      [784, 20]            ├─15,680\n",
      "│    └─bias                                                                        [20]                 └─20\n",
      "├─ReLU: 1-4                              [1, 20]              [1, 20]              --                   --                   --                        --\n",
      "├─Linear: 1-5                            [1, 20]              [1, 10]              --                   210                  True                   1.32%\n",
      "│    └─weight                                                                      [20, 10]             ├─200\n",
      "│    └─bias                                                                        [10]                 └─10\n",
      "================================================================================================================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.02\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.07\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(MODEL, input_size=(1,28,28), \n",
    "        verbose=2, col_names = [\"input_size\", \"output_size\",\"kernel_size\", \"num_params\",\"trainable\", \"params_percent\"], col_width=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.weight torch.Size([20, 784])\n",
      "2.bias torch.Size([20])\n",
      "4.weight torch.Size([10, 20])\n",
      "4.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model.named_parameters()\n",
    "model.parameters()\n",
    "\n",
    "for name, parameter in model.named_parameters():\n",
    "    print(name,parameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Linear(in_features=1,out_features=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same code as Pytorch, easier to read & understand in keras**\n",
    "```python\n",
    "\n",
    "import keras_core as keras\n",
    "from keras import layers, models\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "k_model = models.Sequential([\n",
    "    layers.Input(shape=(28,28,1))                   # LAYER 1: Input Layer\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units = 100, activation=\"relu\"),   # LAYER 2: 1st Hidden Layer with Activation Function\n",
    "    layers.Dense(units = 10 )                       # LAYER 3: Output Layer\n",
    "])\n",
    "k_model.summary()\n",
    "\n",
    "k_model.compile(loss = \"cross_entropy\", optimizer = \"adam\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(MODEL, input_size=(1,28,28), \n",
    "        verbose=2, col_names = [\"input_size\", \"output_size\",\"kernel_size\", \"num_params\",\"trainable\", \"params_percent\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Reducing Error by Looking at Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "loss = error_func( y_predicted_logits, y_actual )\n",
    "de_dw = torch.autograd.grad(outputs= loss, inputs = model.parameters() )\n",
    "loss.backward()\n",
    "```\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial W}\n",
    "$$\n",
    "```python\n",
    "optimizer.step()\n",
    "for parameter in model.parameters():\n",
    "    parameter = parameter - learning_rate * parameter.gradient\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_actual, y_actual = next(iter(train_dataloader))\n",
    "\n",
    "\n",
    "y_predicted_LOGITS = model.forward(input=x_actual)\n",
    "loss               = error_func(y_predicted_LOGITS, y_actual)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "dError_dWeights = torch.autograd.grad(outputs= loss, inputs = list(model.parameters()) )\n",
    "optimizer.step() # SINGLE STEP UPDATES ALL PARAMETERS by one STEP\n",
    "\n",
    "for weight, gradient in zip(model.parameters(), dError_dWeights):\n",
    "    weight = weight - gradient * LEARNING_RATE\n",
    "\n",
    "    print(weight.shape, gradient.shape)\n",
    "    print(weight, gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33majinkyakolhe112\u001b[0m (\u001b[33mm2_mac\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ajinkya/Documents/Visual Studio Code/0_PROJECTS/0 - Cohort-1-DL-101/slides/wandb/run-20231118_195414-ukm8afyo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m2_mac/0%20-%20Cohort-1-DL-101-slides/runs/ukm8afyo' target=\"_blank\">polar-dew-5</a></strong> to <a href='https://wandb.ai/m2_mac/0%20-%20Cohort-1-DL-101-slides' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m2_mac/0%20-%20Cohort-1-DL-101-slides' target=\"_blank\">https://wandb.ai/m2_mac/0%20-%20Cohort-1-DL-101-slides</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m2_mac/0%20-%20Cohort-1-DL-101-slides/runs/ukm8afyo' target=\"_blank\">https://wandb.ai/m2_mac/0%20-%20Cohort-1-DL-101-slides/runs/ukm8afyo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">61</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">58 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>wandb.log(<span style=\"color: #808000; text-decoration-color: #808000\">\"validation_accuracy\"</span>,accuracy_avg)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">59 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">60 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>61 trainer_function(train_dataloader, MODEL, ERROR_FUNC, OPTIMIZER, REPEAT)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">62 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trainer_function</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">43</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"epoch\"</span>: epoch_no                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>}                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">42 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>wandb.log(metrics_per_epoch)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>43 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>evaluate_model(validation_dataset, model, error_func)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate_model</span>(dataset, model, error_func):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model.train(mode=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate_model</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">51</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>loss_total, accuracy_total = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x_actual, y_actual <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> dataset:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>y_predicted_LOGITS = model(x_actual)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>51 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = error_func(y_predicted_LOGITS, y_actual)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>accuracy = torchmetrics.functional.accuracy(y_predicted_LOGITS, y_actual, task=<span style=\"color: #808000; text-decoration-color: #808000\">\"</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss_total = loss_total + loss                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3029</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross_entropy</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3026 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3027 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> size_average <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> reduce <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3028 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>reduction = _Reduction.legacy_get_string(size_average, reduce)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3029 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._C._nn.cross_entropy_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight, _Reduction.get_enum(re  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3030 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3031 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3032 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_cross_entropy</span>(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">cross_entropy_loss</span><span style=\"font-weight: bold\">()</span>: argument <span style=\"color: #008000; text-decoration-color: #008000\">'target'</span> <span style=\"font-weight: bold\">(</span>position <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> must be Tensor, not int\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m61\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m58 \u001b[0m\u001b[2m│   \u001b[0mwandb.log(\u001b[33m\"\u001b[0m\u001b[33mvalidation_accuracy\u001b[0m\u001b[33m\"\u001b[0m,accuracy_avg)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m59 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m60 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m61 trainer_function(train_dataloader, MODEL, ERROR_FUNC, OPTIMIZER, REPEAT)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m62 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrainer_function\u001b[0m:\u001b[94m43\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mepoch\u001b[0m\u001b[33m\"\u001b[0m: epoch_no                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m41 \u001b[0m\u001b[2m│   │   \u001b[0m}                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mwandb.log(metrics_per_epoch)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m43 \u001b[2m│   │   \u001b[0mevaluate_model(validation_dataset, model, error_func)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m45 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mevaluate_model\u001b[0m(dataset, model, error_func):                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   \u001b[0mmodel.train(mode=\u001b[94mFalse\u001b[0m)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mevaluate_model\u001b[0m:\u001b[94m51\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   \u001b[0mloss_total, accuracy_total = \u001b[94m0\u001b[0m, \u001b[94m0\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m x_actual, y_actual \u001b[95min\u001b[0m dataset:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   \u001b[0my_predicted_LOGITS = model(x_actual)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m51 \u001b[2m│   │   \u001b[0mloss = error_func(y_predicted_LOGITS, y_actual)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0maccuracy = torchmetrics.functional.accuracy(y_predicted_LOGITS, y_actual, task=\u001b[33m\"\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   │   \u001b[0mloss_total = loss_total + loss                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m3029\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcross_entropy\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3026 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3027 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m size_average \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m reduce \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3028 \u001b[0m\u001b[2m│   │   \u001b[0mreduction = _Reduction.legacy_get_string(size_average, reduce)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3029 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch._C._nn.cross_entropy_loss(\u001b[96minput\u001b[0m, target, weight, _Reduction.get_enum(re  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3030 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3031 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3032 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbinary_cross_entropy\u001b[0m(                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mcross_entropy_loss\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m: argument \u001b[32m'target'\u001b[0m \u001b[1m(\u001b[0mposition \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m must be Tensor, not int\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "import wandb\n",
    "wandb.init()\n",
    "\n",
    "REPEAT = 10\n",
    "\n",
    "def trainer_function(train_dataloader, model, error_func, optimizer, epochs):\n",
    "    model.train(mode=True)\n",
    "    for epoch_no in range(epochs):\n",
    "\n",
    "        loss_total, accuracy_total = 0, 0\n",
    "        for batch_no, (x_actual, y_actual) in enumerate(train_dataloader):\n",
    "\n",
    "            y_predicted_LOGITS = model.forward(x_actual)\n",
    "            y_predicted_probs  = nn.functional.softmax(y_predicted_LOGITS, dim= 1)\n",
    "            loss               = error_func(y_predicted_LOGITS, y_actual)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_batch = loss.item()\n",
    "            accuracy_batch = torchmetrics.functional.accuracy(y_predicted_LOGITS, y_actual, task=\"multiclass\", num_classes=10)\n",
    "            \n",
    "            loss_total = loss_total + loss_batch \n",
    "            accuracy_total = accuracy_total + accuracy_batch\n",
    "            metrics_per_batch = {\n",
    "                \"loss\": loss_batch,\n",
    "                \"accuracy_batch\": accuracy_batch,\n",
    "                \"batch_no\": batch_no\n",
    "            }\n",
    "            wandb.log(metrics_per_batch)\n",
    "            # dError_dWeights = torch.autograd.grad(outputs= loss, inputs = model.parameters() )\n",
    "            # for parameter, gradient in zip(model.parameters(), dError_dWeights):\n",
    "            #     parameter = parameter - gradient * learning_rate\n",
    "        \n",
    "        accuracy_average = accuracy_total / TOTAL_BATCHES\n",
    "        metrics_per_epoch = {\n",
    "            \"train_accuracy_epoch\": accuracy_average,\n",
    "            \"epoch\": epoch_no\n",
    "        }\n",
    "        wandb.log(metrics_per_epoch)\n",
    "        evaluate_model(validation_dataset, model, error_func)\n",
    "\n",
    "def evaluate_model(dataset, model, error_func):\n",
    "    model.train(mode=False)\n",
    "\n",
    "    loss_total, accuracy_total = 0, 0\n",
    "    for x_actual, y_actual in validation_dataloader:\n",
    "        y_predicted_LOGITS = model(x_actual)\n",
    "        loss = error_func(y_predicted_LOGITS, y_actual)\n",
    "        accuracy = torchmetrics.functional.accuracy(y_predicted_LOGITS, y_actual, task=\"multiclass\", num_classes=10)\n",
    "        \n",
    "        loss_total = loss_total + loss \n",
    "        accuracy_total = accuracy_total + accuracy\n",
    "    \n",
    "    accuracy_avg = accuracy_total / len(dataset)\n",
    "    wandb.log(\"validation_accuracy\",accuracy_avg)\n",
    "    \n",
    "\n",
    "trainer_function(train_dataloader, MODEL, ERROR_FUNC, OPTIMIZER, REPEAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Brain vs Artificial Neural Network\n",
    "\n",
    "- The brain does not learn by implementing a single, global optimization principle within a uniform and undifferentiated neural network.\n",
    "- Rather, biological brains are modular, with distinct but interacting subsystems underpinning key functions such as memory, language, and cognitive control\n",
    "- The primate visual system works differently. Rather than processing all input in parallel, visual attention shifts strategically among locations and objects, centering processing resources and representational coordinates on a series of regions in turn\n",
    "- Continual Learning is an ability to master new tasks without forgetting how to perform prior tasks. Brain does continual Learning easily. Neural Networks can't do that.They do Catastrophic Forgetting\n",
    "- Efficient Learning: ability to rapidly learn about new concepts from only a handful of examples\n",
    "- Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks in more Detail\n",
    "\n",
    "### 7 Steps to Learned Neural Network\n",
    "1. Dataset in Detail\n",
    "2. Neural Network Forward Pass & Dot Product & Activation\n",
    "3. Error Function & Calculation for each Data\n",
    "4. Error Gradient Calculation / Backward Pass\n",
    "5. PARAMETER update in direction of Error Reduction. Model Training Monitoring\n",
    "6. Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: MODEL \n",
    "feature_extractor = nn.Sequential(\n",
    "    nn.Conv2d( out_channels = 50, in_channels = 1, kernel_size = (3,3) , padding=\"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2,2), stride = 2),\n",
    "  \n",
    "    nn.Conv2d(out_channels = 100, in_channels = 50, kernel_size = (3,3), padding=\"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2,2), stride = 2),\n",
    "\n",
    ")\n",
    "\n",
    "decision_maker = nn.Sequential(\n",
    "  nn.Linear(out_features = 50, in_features = 100*7*7 ),\n",
    "  nn.Linear(out_features = 10, in_features = 50)\n",
    ")\n",
    "\n",
    "model = nn.Sequential(\n",
    "  feature_extractor,\n",
    "  decision_maker\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest\n",
    "\n",
    "##### Types of Intelligence\n",
    "1. No Intelligence      - \n",
    "1. Narrow Intelligence  - Single Task Intelligence\n",
    "1. General Intelligence - Multiple Tasks Intelligence\n",
    "1. Super Intelligence   - More tasks than possible by Single Human\n",
    "\n",
    "---\n",
    "##### Complexity of Intelligence\n",
    "1. Standing Up & Picking Up a Pen\n",
    "2. Identifying an Object\n",
    "3. Understanding Words\n",
    "---\n",
    "##### Possible Applications via Flexibility\n",
    "1. Robotics\n",
    "2. Visual Factory Hand \n",
    "3. ChatGPT+\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
