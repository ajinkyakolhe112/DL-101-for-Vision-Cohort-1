{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 - Building Neural Network for Intelligence\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Section 1: Natural Intelligence = Brain\n",
    "\n",
    "#### Electrical Brain\n",
    "1. Group of Interconnected Wires (Neuron Connections) with different amount of Fat Insulation (Myelination)\n",
    "2. Carrying electrical signals (Data)\n",
    "\n",
    "#### Network Brain\n",
    "Brain is a\n",
    "1. Large \n",
    "2. Interconnected\n",
    "3. Network of\n",
    "4. Neurons\n",
    "   1. Group of Neurons at same level are called Layer\n",
    "5. Check [Brain Neural Network](http://nxxcxx.github.io/Neural-Network/)\n",
    "\n",
    "#### Single Neuron - 3 Things\n",
    "1. Input Data through Wire\n",
    "2. Wire with varying Insulation Strength via Mylenation\n",
    "3. Output Connection\n",
    "\n",
    "#### Single Neuron Diagram\n",
    "![Biological Neuron Model](https://www.researchgate.net/publication/341241129/figure/fig1/AS:888908187443205@1588943635819/Biological-Neuron-Model.ppm)\n",
    "![Single Neuron](https://media.geeksforgeeks.org/wp-content/uploads/20230410104038/Artificial-Neural-Networks.webp)\n",
    "![Layers of Neurons](https://qph.cf2.quoracdn.net/main-qimg-084ade3ed1f8a97709e374090a92e1ca.webp)\n",
    "\n",
    "#### Brain as Layered Neural Network\n",
    "![Visual Processing in Brain](https://neuwritesd.files.wordpress.com/2015/10/visual_stream_small.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Artificial Intelligence\n",
    "\n",
    "Brute Force Error Minimizer from Data\n",
    "\n",
    "```python\n",
    "\n",
    "for each x_actual & y_actual in train_data_loader:\n",
    "    y_predicted_LOGITS = model(x_actual)\n",
    "    loss               = error_func(y_predicted_LOGITS, y_actual)\n",
    "\n",
    "    dError_dWeights = torch.autograd.grad(outputs= loss, inputs = model.parameters() )\n",
    "    for weight, gradient in zip(model.parameters(), dError_dWeights):\n",
    "        weight = weight - gradient * learning_rate\n",
    "        print(weight.shape, gradient.shape)\n",
    "        print(weight, gradient)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network in Pytorch\n",
    "Neural Network has 4 Steps\n",
    "1. Data\n",
    "2. Model Architecture\n",
    "3. Model Training\n",
    "4. Model Evaluation\n",
    "\n",
    "Model Training has 5 Steps\n",
    "1. Predict from Existing Weight Values. (Network)\n",
    "2. Calculate Error of Prediction wrt y_actual\n",
    "3. Clear dError_dWeights\n",
    "4. Calculate dError_dWeights\n",
    "5. $ w = w - \\nabla * lr $\n",
    "\n",
    "$\\large trained\\_model = \\operatorname*{argmin}_{\\mathbf{w}, b}\\  Loss( y_{predicted}, y_{actual})\\\\$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install wandb\n",
    "!pip install torchmetrics\n",
    "!pip install torchinfo\n",
    "!pip install torchvision\n",
    "!pip install ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch , torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# ! KEY CODE\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import datasets as huggingface_datasets\n",
    "import ipyplot\n",
    "\n",
    "# 1. Download Dataset from Huggingface\n",
    "training_dataset = huggingface_datasets.load_dataset(\"mnist\", split=\"train\")\n",
    "hg_dataset_split = training_dataset.train_test_split(train_size=0.9, test_size=0.1)\n",
    "training_dataset, validation_dataset    = hg_dataset_split['train'], hg_dataset_split['test']\n",
    "\n",
    "# 2. Plot multiple Images. (Image format not Tensor)\n",
    "ipyplot.plot_images(training_dataset['image'][0:5]);\n",
    "\n",
    "# 3. Dataset -> Pytorch Tensors\n",
    "training_dataset.set_format(type='torch', format_kwargs={\"dtype\": torch.float32})\n",
    "training_dataset = training_dataset.with_format(\"torch\")\n",
    "\n",
    "# 4. Pytorch Dataset -> Data Loader\n",
    "BATCH_SIZE = 4\n",
    "TOTAL_BATCHES = len(training_dataset) / BATCH_SIZE\n",
    "training_data_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size= BATCH_SIZE)\n",
    "# X_BATCH, Y_BATCH = next(iter(training_dataloader))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        #ipyplot-html-viewer-toggle-fKPruSc2jcAUNUGNzLPby5 {\n",
       "            position: absolute;\n",
       "            top: -9999px;\n",
       "            left: -9999px;\n",
       "            visibility: hidden;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-label-fKPruSc2jcAUNUGNzLPby5 { \n",
       "            position: relative;\n",
       "            display: inline-block;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-textarea-fKPruSc2jcAUNUGNzLPby5 {\n",
       "            background: lightgrey;\n",
       "            width: 100%;\n",
       "            height: 0px;\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-fKPruSc2jcAUNUGNzLPby5:checked ~ #ipyplot-html-viewer-textarea-fKPruSc2jcAUNUGNzLPby5 {\n",
       "            height: 200px;\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-fKPruSc2jcAUNUGNzLPby5:checked + #ipyplot-html-viewer-label-fKPruSc2jcAUNUGNzLPby5:after {\n",
       "            content: \"hide html\";\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            right: 0;\n",
       "            bottom: 0;\n",
       "            background: white;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <input type=\"checkbox\" id=\"ipyplot-html-viewer-toggle-fKPruSc2jcAUNUGNzLPby5\">\n",
       "        <label id=\"ipyplot-html-viewer-label-fKPruSc2jcAUNUGNzLPby5\" for=\"ipyplot-html-viewer-toggle-fKPruSc2jcAUNUGNzLPby5\">show html</label>\n",
       "        <textarea id=\"ipyplot-html-viewer-textarea-fKPruSc2jcAUNUGNzLPby5\" readonly>\n",
       "            \n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-ERFSr9ZAC7ybtM6xTRsKCs {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-ERFSr9ZAC7ybtM6xTRsKCs {\n",
       "            width: 150px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs {\n",
       "            width: 150px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs img {\n",
       "            width: 150px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-ERFSr9ZAC7ybtM6xTRsKCs\">\n",
       "    <div class=\"ipyplot-placeholder-div-ERFSr9ZAC7ybtM6xTRsKCs\">\n",
       "        <div id=\"ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs-e7455sbzKb8gX2RAEgE3xu\" class=\"ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1UlEQVR4nGNgGEqAEcZQ0GS4psB1xoTh4DdMVbm//+5983vd39/KmHIKz3///f37928USSYozSqCxU6Y5LOZhFzXxMDw/y8WO2EAq51QMAeFxwKh7B/4MTD+Z2AwZ2CIfcvAePCi/oeHsEAwXfHamIHpHwMDlLj6SP6rBUx/7d+/f//+RyUYYDr/IjTBCVaYnbdFPvxm4JFgYGD4+pSBgYFR5MPveoS7gkUYGLT65v3+nQ7nogPV37+xeQUCTNB8jQJu/p6MwkdTuwW3sYuFHuExl2oAAMMOVYp0OlrQAAAAAElFTkSuQmCC\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs-e7455sbzKb8gX2RAEgE3xu\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>\n",
       "        </textarea>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-ERFSr9ZAC7ybtM6xTRsKCs {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-ERFSr9ZAC7ybtM6xTRsKCs {\n",
       "            width: 150px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs {\n",
       "            width: 150px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs img {\n",
       "            width: 150px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-ERFSr9ZAC7ybtM6xTRsKCs\">\n",
       "    <div class=\"ipyplot-placeholder-div-ERFSr9ZAC7ybtM6xTRsKCs\">\n",
       "        <div id=\"ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs-e7455sbzKb8gX2RAEgE3xu\" class=\"ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1UlEQVR4nGNgGEqAEcZQ0GS4psB1xoTh4DdMVbm//+5983vd39/KmHIKz3///f37928USSYozSqCxU6Y5LOZhFzXxMDw/y8WO2EAq51QMAeFxwKh7B/4MTD+Z2AwZ2CIfcvAePCi/oeHsEAwXfHamIHpHwMDlLj6SP6rBUx/7d+/f//+RyUYYDr/IjTBCVaYnbdFPvxm4JFgYGD4+pSBgYFR5MPveoS7gkUYGLT65v3+nQ7nogPV37+xeQUCTNB8jQJu/p6MwkdTuwW3sYuFHuExl2oAAMMOVYp0OlrQAAAAAElFTkSuQmCC\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-ERFSr9ZAC7ybtM6xTRsKCs-e7455sbzKb8gX2RAEgE3xu\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ! KEY CODE\n",
    "\n",
    "from torchvision import datasets as torchvision_datasets\n",
    "from torchvision import transforms as torchvision_transforms\n",
    "import ipyplot\n",
    "\n",
    "# 1. Download Dataset from Available once in torchvision_datasets\n",
    "training_dataset = torchvision_datasets.MNIST( root= '../dataset', transform= torchvision_transforms.ToTensor(), train= True, download= True )\n",
    "training_dataset, validation_dataset = torch.utils.data.random_split(training_dataset, [0.9, 0.1])\n",
    "\n",
    "# 2. Plot Image\n",
    "x,y = training_dataset[0]\n",
    "ipyplot.plot_images(x);\n",
    "\n",
    "# 3. Dataset -> Pytorch Tensors\n",
    "pass\n",
    "\n",
    "# 4. Pytorch Dataset -> Data Loader\n",
    "BATCH_SIZE = 4\n",
    "TOTAL_BATCHES = len(training_dataset) / BATCH_SIZE\n",
    "\n",
    "training_dataloader   = torch.utils.data.DataLoader( dataset= training_dataset  , batch_size= BATCH_SIZE, shuffle= True )\n",
    "validation_dataloader = torch.utils.data.DataLoader( dataset= validation_dataset, batch_size= BATCH_SIZE, shuffle= True )\n",
    "X_BATCH, Y_BATCH = next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1905], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.1053],\n",
      "        [ 0.0142],\n",
      "        [-0.1397],\n",
      "        [-0.4612],\n",
      "        [ 0.4644],\n",
      "        [ 0.2745],\n",
      "        [-0.5693],\n",
      "        [ 0.3611],\n",
      "        [ 0.3861],\n",
      "        [ 0.1093]], grad_fn=<AddmmBackward0>)\n",
      "X vector is= tensor([-0.5936, -0.3838])\n",
      "Weights vector is = Parameter containing:\n",
      "tensor([[ 0.2785, -0.1303]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(in_features = 2, out_features = 1)\n",
    "layer = nn.Linear(out_features = 1, in_features = 2)\n",
    "\n",
    "x = torch.randn(2)\n",
    "x_batch = torch.randn(10,2)\n",
    "\n",
    "# Forward Pass\n",
    "print(layer.forward(x))\n",
    "print(layer.forward(x_batch))\n",
    "\n",
    "# Dot Product = Weighted Sum\n",
    "print(f'X vector is= {x}')\n",
    "print(f'Weights vector is = {layer.weight}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([20, 784])\n",
      "bias torch.Size([20])\n",
      "Entire Layer Parameters torch.Size([20, 784]) torch.Size([20])\n",
      "3rd Neurons Parameters weight = torch.Size([784]), bias = -0.020121073350310326\n",
      "Will gradients be calculated? True\n",
      "Parameters => Parameter containing:\n",
      "tensor([[ 0.0123, -0.0293,  0.0221,  ..., -0.0339,  0.0101,  0.0162],\n",
      "        [-0.0208, -0.0229,  0.0126,  ...,  0.0159,  0.0226,  0.0337],\n",
      "        [-0.0082, -0.0053, -0.0338,  ..., -0.0116, -0.0308, -0.0094],\n",
      "        ...,\n",
      "        [ 0.0107,  0.0118,  0.0335,  ..., -0.0225,  0.0007, -0.0254],\n",
      "        [ 0.0007,  0.0068, -0.0327,  ...,  0.0096,  0.0176, -0.0030],\n",
      "        [-0.0164,  0.0103, -0.0133,  ...,  0.0150,  0.0282, -0.0066]],\n",
      "       requires_grad=True)\n",
      "Gradient dError_dParameters => None\n"
     ]
    }
   ],
   "source": [
    "# Neural Network for Digits Dataset\n",
    "import torch, torch.nn as nn\n",
    "\n",
    "input_layer = nn.Identity()\n",
    "layer_1     = nn.Linear(out_features= 20, in_features=28*28*1)\n",
    "layer_2     = nn.Linear(out_features= 10, in_features=20)\n",
    "\n",
    "# Finding Parameters of layer. Method `named_parameters`\n",
    "for name, parameter in layer_1.named_parameters():\n",
    "    print(name, parameter.shape)\n",
    "\n",
    "# Using Parameter Name Directly. weight\n",
    "print(\"Entire Layer Parameters\", layer_1.weight.shape, layer_1.bias.shape)\n",
    "print(f'3rd Neurons Parameters weight = {layer_1.weight[2].shape}, bias = {layer_1.bias[2]}')\n",
    "\n",
    "# Important Properties of Parameters\n",
    "print(\"Will gradients be calculated?\", layer_1.weight.requires_grad)\n",
    "print(\"Parameters =>\", layer_1.weight)\n",
    "print(\"Gradient dError_dParameters =>\", layer_1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape              Param #                   Trainable                 Param %\n",
      "==============================================================================================================================================================================================\n",
      "Linear                                   [784]                     [20]                      --                        15,700                    True                      100.00%\n",
      "├─weight                                                                                     [784, 20]                 ├─15,680\n",
      "├─bias                                                                                       [20]                      └─20\n",
      "==============================================================================================================================================================================================\n",
      "Total params: 15,700\n",
      "Trainable params: 15,700\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.31\n",
      "==============================================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.07\n",
      "==============================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(layer_1, input_size=(1*28*28,), \n",
    "        verbose=2, col_names = [\"input_size\", \"output_size\",\"kernel_size\", \"num_params\",\"trainable\", \"params_percent\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = X \\odot W + b$\n",
    "\n",
    "```python\n",
    "import keras_core as keras\n",
    "import torch\n",
    "\n",
    "keras.layers.Input()\n",
    "keras.layers.Dense(units = 4, activation=\"relu\")\n",
    "keras.layers.Dense(units = 8)\n",
    "keras.layers.Dense(units = 14)\n",
    "\n",
    "torch.nn.Linear(4, in_features= 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape              Param #                   Trainable                 Param %\n",
      "==============================================================================================================================================================================================\n",
      "Sequential                               [1, 28, 28]               [1, 10]                   --                        --                        True                           --\n",
      "├─Flatten: 1-1                           [1, 28, 28]               [1, 784]                  --                        --                        --                             --\n",
      "├─Identity: 1-2                          [1, 784]                  [1, 784]                  --                        --                        --                             --\n",
      "├─Linear: 1-3                            [1, 784]                  [1, 20]                   --                        15,700                    True                       98.68%\n",
      "│    └─weight                                                                                [784, 20]                 ├─15,680\n",
      "│    └─bias                                                                                  [20]                      └─20\n",
      "├─ReLU: 1-4                              [1, 20]                   [1, 20]                   --                        --                        --                             --\n",
      "├─Linear: 1-5                            [1, 20]                   [1, 10]                   --                        210                       True                        1.32%\n",
      "│    └─weight                                                                                [20, 10]                  ├─200\n",
      "│    └─bias                                                                                  [10]                      └─10\n",
      "==============================================================================================================================================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.02\n",
      "==============================================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.07\n",
      "==============================================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajinkya/opt/anaconda3/lib/python3.9/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n"
     ]
    }
   ],
   "source": [
    "# ! KEY CODE\n",
    "\n",
    "from torch.nn import ReLU as ActivatePositive\n",
    "\n",
    "# 1. Model Architecture - [20 neurons, 10 neurons]\n",
    "# network = input -> Linear 20 -> Linear 10 = output\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1), # IMAGE RESHAPE from 2D(28,28) -> 1D(28*28)\n",
    "    \n",
    "    nn.Identity(),                                                              # LAYER 1: INPUT LAYER\n",
    "    nn.Linear(out_features = 20, in_features = 28*28*1), ActivatePositive(),    # LAYER 2: 1st Hidden Layer\n",
    "    nn.Linear(out_features = 10 , in_features = 20),                            # LAYER 3: Output Layer\n",
    ")\n",
    "\n",
    "# 2. Model Parameters & Their Relationship with Error\n",
    "model_parameters = list(model.parameters())\n",
    "\n",
    "# 3. Registering Model Parameters with Optimizer, as variables to be minimized\n",
    "gradient_step    = 10\n",
    "LEARNING_RATE    = gradient_step\n",
    "OPTIMIZER        = torch.optim.SGD( params= model_parameters, lr= gradient_step )\n",
    "\n",
    "# 4. Calculation of Error of Prediction\n",
    "ERROR_FUNC = nn.functional.cross_entropy\n",
    "\n",
    "# 5. Calculation of relationship of Error & Parameters\n",
    "X_BATCH, Y_BATCH = next(iter(training_dataloader))\n",
    "GRADIENTS_accumulated = torch.autograd.grad(outputs = ERROR_FUNC(model(X_BATCH), Y_BATCH), inputs = model_parameters)\n",
    "# loss.backward(), computes dloss/dw for every parameter w which has requires_grad=True.\n",
    "# w.grad += dloss/dw\n",
    "# By default, gradients are accumulated in buffers (i.e, not overwritten) whenever .backward() is called.\n",
    "\n",
    "# 6. Model Layers, Parameters Visualization\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1,28,28), \n",
    "        verbose=2, col_names = [\"input_size\", \"output_size\",\"kernel_size\", \"num_params\",\"trainable\", \"params_percent\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same code as Pytorch, easier to read & understand in keras**\n",
    "```python\n",
    "\n",
    "import keras_core as keras\n",
    "from keras import layers, models\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "k_model = models.Sequential([\n",
    "    layers.Input(shape=(28,28,1))                   # LAYER 1: Input Layer\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units = 100, activation=\"relu\"),   # LAYER 2: 1st Hidden Layer with Activation Function\n",
    "    layers.Dense(units = 10 )                       # LAYER 3: Output Layer\n",
    "])\n",
    "k_model.summary()\n",
    "\n",
    "k_model.compile(loss = \"cross_entropy\", optimizer = \"adam\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Reducing Error by Looking at Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "loss = error_func( y_predicted_logits, y_actual )\n",
    "de_dw = torch.autograd.grad(outputs= loss, inputs = model.parameters() )\n",
    "loss.backward()\n",
    "\n",
    "parameters_list = list(model.parameters())\n",
    "gradients_list = list(de_dw)\n",
    "\n",
    "optimizer.step()\n",
    "for parameter in model.parameters():\n",
    "    parameter = parameter - step_length * parameter.gradient\n",
    "```\n",
    "$\\Huge \\frac{\\partial E}{\\partial W}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.weight\n",
      "weight & gradient shape =  torch.Size([20, 784]) torch.Size([20, 784])\n",
      "weight & gradient values=  tensor([[ 0.0007,  0.0313, -0.0111,  ..., -0.0171, -0.0164, -0.0328],\n",
      "        [ 0.0052,  0.0043, -0.0242,  ...,  0.0071, -0.0301,  0.0218],\n",
      "        [ 0.0202,  0.0034,  0.0308,  ...,  0.0203, -0.0304,  0.0334],\n",
      "        ...,\n",
      "        [ 0.0182,  0.0347, -0.0090,  ...,  0.0219,  0.0026, -0.0165],\n",
      "        [-0.0248,  0.0065, -0.0276,  ..., -0.0066, -0.0177, -0.0129],\n",
      "        [-0.0258,  0.0085, -0.0303,  ..., -0.0304,  0.0135, -0.0334]],\n",
      "       grad_fn=<SubBackward0>) tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "non zero gradients tensor(4030)\n",
      "2.bias\n",
      "weight & gradient shape =  torch.Size([20]) torch.Size([20])\n",
      "weight & gradient values=  tensor([-0.0005,  0.0033,  0.0067, -0.0061,  0.0218, -0.0141, -0.0071,  0.0008,\n",
      "         0.0054, -0.0222,  0.0024,  0.0201,  0.0031,  0.0213,  0.0303, -0.0314,\n",
      "         0.0048, -0.0320,  0.0189,  0.0277], grad_fn=<SubBackward0>) tensor([ 0.0528, -0.0158, -0.0401,  0.0000, -0.0168, -0.0144,  0.0000,  0.0441,\n",
      "        -0.0189,  0.0727,  0.0000, -0.0477, -0.0598,  0.0000,  0.0000, -0.0385,\n",
      "         0.0000,  0.0035, -0.0101,  0.0487])\n",
      "non zero gradients tensor(14)\n",
      "4.weight\n",
      "weight & gradient shape =  torch.Size([10, 20]) torch.Size([10, 20])\n",
      "weight & gradient values=  tensor([[ 0.0025, -0.1611, -0.1404, -0.1394,  0.0135,  0.0017, -0.1328, -0.0957,\n",
      "          0.1222,  0.1165,  0.0811,  0.0709, -0.1552, -0.1092, -0.1414, -0.0613,\n",
      "          0.0579, -0.1386, -0.0888, -0.1544],\n",
      "        [ 0.1886, -0.0557, -0.0423,  0.0044,  0.0683, -0.1825, -0.0856,  0.0270,\n",
      "          0.0532,  0.1687,  0.1866, -0.0405, -0.0042, -0.0632, -0.1590, -0.1642,\n",
      "          0.0776,  0.1806, -0.0779, -0.1899],\n",
      "        [ 0.1529,  0.0431,  0.0308, -0.1717,  0.1848, -0.0923,  0.0269, -0.0240,\n",
      "         -0.1363,  0.1545,  0.1172,  0.0149, -0.1173,  0.0782,  0.1884, -0.1568,\n",
      "          0.0920, -0.1122,  0.1277,  0.0085],\n",
      "        [-0.0590, -0.1598, -0.1290,  0.0196, -0.1432,  0.1793, -0.1521,  0.1868,\n",
      "          0.2179,  0.1847, -0.0391,  0.1644, -0.1941, -0.0884,  0.0930,  0.0992,\n",
      "          0.2162, -0.1669,  0.1117, -0.0272],\n",
      "        [ 0.0212, -0.0756, -0.1075, -0.1115, -0.1090, -0.1295, -0.0779,  0.0269,\n",
      "          0.1030,  0.0165,  0.2050, -0.1149,  0.2002, -0.1713,  0.0337,  0.1154,\n",
      "          0.1723,  0.1206, -0.1034,  0.0162],\n",
      "        [-0.0781, -0.0336,  0.1391, -0.1055,  0.0091, -0.1118, -0.2175, -0.0418,\n",
      "          0.0783, -0.1789, -0.1676,  0.1324,  0.0971, -0.1978,  0.2035,  0.0425,\n",
      "          0.1438, -0.0531, -0.1766, -0.1626],\n",
      "        [ 0.1915,  0.0893,  0.0185, -0.1488,  0.1477,  0.2140, -0.0259, -0.1084,\n",
      "         -0.0980,  0.0253,  0.1526, -0.0719,  0.0557,  0.0137,  0.1911,  0.1645,\n",
      "          0.1768, -0.0109, -0.0698,  0.0276],\n",
      "        [ 0.1131, -0.2116, -0.0265,  0.2076,  0.0252,  0.0939,  0.0852,  0.0038,\n",
      "         -0.1867,  0.1526, -0.2236,  0.1104, -0.1901,  0.0538,  0.1465, -0.1512,\n",
      "          0.0733, -0.1043, -0.0004, -0.1666],\n",
      "        [ 0.1754,  0.1110,  0.1348,  0.1730,  0.1596,  0.1743,  0.1132, -0.1193,\n",
      "         -0.0446,  0.1261,  0.1886,  0.1119, -0.1382,  0.1134, -0.1871, -0.0216,\n",
      "          0.1104, -0.0731, -0.1928, -0.1095],\n",
      "        [-0.1837, -0.2154, -0.0953, -0.0163, -0.0349,  0.0950,  0.0425,  0.0720,\n",
      "         -0.1601, -0.1376, -0.0358, -0.1405, -0.0292,  0.1678, -0.2122, -0.0830,\n",
      "         -0.1962,  0.1837, -0.1897,  0.1069]], grad_fn=<SubBackward0>) tensor([[ 0.0063,  0.0169,  0.0030,  0.0000,  0.0174,  0.0003,  0.0000,  0.0115,\n",
      "          0.0004,  0.0097,  0.0000,  0.0307,  0.0059,  0.0000,  0.0000,  0.0087,\n",
      "          0.0000,  0.0050,  0.0087,  0.0023],\n",
      "        [ 0.0058,  0.0154,  0.0027,  0.0000,  0.0161,  0.0003,  0.0000,  0.0106,\n",
      "          0.0004,  0.0091,  0.0000,  0.0282,  0.0055,  0.0000,  0.0000,  0.0081,\n",
      "          0.0000,  0.0047,  0.0078,  0.0021],\n",
      "        [ 0.0070,  0.0192,  0.0033,  0.0000,  0.0194,  0.0004,  0.0000,  0.0127,\n",
      "          0.0005,  0.0108,  0.0000,  0.0344,  0.0065,  0.0000,  0.0000,  0.0097,\n",
      "          0.0000,  0.0056,  0.0100,  0.0026],\n",
      "        [ 0.0077,  0.0193,  0.0034,  0.0000,  0.0205,  0.0004,  0.0000,  0.0139,\n",
      "          0.0005,  0.0113,  0.0000,  0.0365,  0.0066,  0.0000,  0.0000,  0.0105,\n",
      "          0.0000,  0.0060,  0.0099,  0.0028],\n",
      "        [ 0.0067,  0.0183,  0.0032,  0.0000,  0.0189,  0.0004,  0.0000,  0.0124,\n",
      "          0.0004,  0.0108,  0.0000,  0.0329,  0.0067,  0.0000,  0.0000,  0.0094,\n",
      "          0.0000,  0.0055,  0.0093,  0.0025],\n",
      "        [-0.0516, -0.0485, -0.0262,  0.0000, -0.0836, -0.0006,  0.0000, -0.0939,\n",
      "         -0.0036, -0.0284,  0.0000, -0.1910, -0.0079,  0.0000,  0.0000, -0.0557,\n",
      "          0.0000, -0.0296,  0.0088, -0.0207],\n",
      "        [ 0.0070, -0.0103,  0.0033,  0.0000, -0.0228, -0.0020,  0.0000,  0.0040,\n",
      "          0.0005, -0.0474,  0.0000,  0.0144, -0.0379,  0.0000,  0.0000, -0.0057,\n",
      "          0.0000, -0.0098, -0.0052,  0.0026],\n",
      "        [ 0.0014, -0.0560,  0.0028,  0.0000, -0.0123,  0.0003,  0.0000,  0.0111,\n",
      "          0.0004,  0.0093,  0.0000, -0.0330,  0.0055,  0.0000,  0.0000,  0.0016,\n",
      "          0.0000,  0.0049, -0.0623,  0.0023],\n",
      "        [ 0.0052,  0.0137,  0.0025,  0.0000,  0.0142,  0.0003,  0.0000,  0.0095,\n",
      "          0.0003,  0.0078,  0.0000,  0.0252,  0.0047,  0.0000,  0.0000,  0.0072,\n",
      "          0.0000,  0.0041,  0.0069,  0.0019],\n",
      "        [ 0.0044,  0.0120,  0.0021,  0.0000,  0.0123,  0.0002,  0.0000,  0.0081,\n",
      "          0.0003,  0.0070,  0.0000,  0.0216,  0.0043,  0.0000,  0.0000,  0.0062,\n",
      "          0.0000,  0.0036,  0.0061,  0.0016]])\n",
      "non zero gradients tensor(140)\n",
      "4.bias\n",
      "weight & gradient shape =  torch.Size([10]) torch.Size([10])\n",
      "weight & gradient values=  tensor([ 0.0943, -0.0334,  0.1204,  0.1718,  0.1825,  0.0946,  0.1335,  0.0148,\n",
      "        -0.2155, -0.1668], grad_fn=<SubBackward0>) tensor([ 0.1010,  0.0927,  0.1133,  0.1169,  0.1097, -0.3955, -0.1375, -0.1543,\n",
      "         0.0819,  0.0718])\n",
      "non zero gradients tensor(10)\n"
     ]
    }
   ],
   "source": [
    "x_actual, y_actual = next(iter(training_dataloader))\n",
    "\n",
    "\n",
    "y_predicted_LOGITS = model.forward(input=x_actual)\n",
    "loss               = ERROR_FUNC(y_predicted_LOGITS, y_actual)\n",
    "model_parameters   = list(model.parameters())\n",
    "\n",
    "OPTIMIZER.zero_grad()\n",
    "# loss.backward()\n",
    "# loss.backward(), computes dloss/dw for every parameter w which has requires_grad=True.\n",
    "# w.grad += dloss/dw. By default, gradients are accumulated in buffers (i.e, not overwritten) whenever .backward() is called.\n",
    "dError_dWeights = torch.autograd.grad(outputs= loss, inputs = model_parameters)\n",
    "\n",
    "# SINGLE STEP UPDATES ALL PARAMETERS by one STEP\n",
    "OPTIMIZER.step() \n",
    "\n",
    "for (name, weight), gradient in zip(model.named_parameters(), dError_dWeights):\n",
    "    print(name)\n",
    "    weight = weight - gradient * LEARNING_RATE\n",
    "\n",
    "    print(\"weight & gradient shape = \", weight.shape, gradient.shape)\n",
    "    print(\"weight & gradient values= \", weight, gradient)\n",
    "    print(\"non zero gradients\", torch.count_nonzero(gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! KEY CODE\n",
    "\n",
    "import torchmetrics\n",
    "import wandb\n",
    "wandb.init()\n",
    "\n",
    "REPEAT = 10\n",
    "\n",
    "def trainer_function(training_dataloader, model, error_func, optimizer, epochs):\n",
    "    model.train(mode=True)\n",
    "\n",
    "    for epoch_no in range(epochs):\n",
    "\n",
    "        loss_total, accuracy_total = 0, 0\n",
    "        for batch_no, (x_actual, y_actual) in enumerate(training_dataloader):\n",
    "\n",
    "            y_predicted_LOGITS = model.forward(x_actual)\n",
    "            y_predicted_probs  = nn.functional.softmax(y_predicted_LOGITS, dim= 1)\n",
    "            loss               = error_func(y_predicted_LOGITS, y_actual)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_batch      = loss.item()\n",
    "            accuracy_batch  = torchmetrics.functional.accuracy(y_predicted_LOGITS, y_actual, task=\"multiclass\", num_classes=10)\n",
    "            \n",
    "            loss_total      = loss_total + loss_batch \n",
    "            accuracy_total  = accuracy_total + accuracy_batch\n",
    "            \n",
    "            metrics_per_batch = {\n",
    "                \"loss\": loss_batch,\n",
    "                \"accuracy_batch\": accuracy_batch,\n",
    "                \"accuracy_average\": accuracy_total / (batch_no + 1),\n",
    "                \"batch_no\": batch_no\n",
    "            }\n",
    "            wandb.log(metrics_per_batch)\n",
    "            print(\"END OF BATCH\")\n",
    "            \"\"\"\n",
    "            # Alternative Training Loop\n",
    "            \n",
    "            OPTIMIZER.zero_grad()\n",
    "            # loss.backward()\n",
    "            # loss.backward(), computes dloss/dw for every parameter w which has requires_grad=True.\n",
    "            # w.grad += dloss/dw. By default, gradients are accumulated in buffers (i.e, not overwritten) whenever .backward() is called.\n",
    "            dError_dWeights = torch.autograd.grad(outputs= loss, inputs = model_parameters)\n",
    "\n",
    "            # SINGLE STEP UPDATES ALL PARAMETERS by one STEP\n",
    "            OPTIMIZER.step()\n",
    "            for (name, weight), gradient in zip(model.named_parameters(), dError_dWeights):\n",
    "                print(name)\n",
    "                weight = weight - gradient * LEARNING_RATE\n",
    "            \"\"\"\n",
    "            print(\"END OF BATCH\")\n",
    "        \n",
    "        accuracy_average    = accuracy_total / TOTAL_BATCHES\n",
    "        metrics_per_epoch   = {\n",
    "            \"training_accuracy_average_per_epoch\": accuracy_average\n",
    "        }\n",
    "        wandb.log(metrics_per_epoch)\n",
    "        print(f\"END OF ENTIRE EPOCH no {epoch_no}\")\n",
    "        evaluate_model(validation_dataset, model, error_func, epoch_no)\n",
    "\n",
    "def evaluate_model(dataset, model, error_func, epoch_no):\n",
    "    model.train(mode=False)\n",
    "\n",
    "    loss_total, accuracy_total = 0, 0\n",
    "    for x_actual, y_actual in validation_dataloader:\n",
    "        y_predicted_LOGITS = model(x_actual)\n",
    "        loss = error_func(y_predicted_LOGITS, y_actual)\n",
    "        accuracy = torchmetrics.functional.accuracy(y_predicted_LOGITS, y_actual, task=\"multiclass\", num_classes=10)\n",
    "        \n",
    "        loss_total = loss_total + loss \n",
    "        accuracy_total = accuracy_total + accuracy\n",
    "    \n",
    "    accuracy_average = accuracy_total / len(dataset)\n",
    "    wandb.log({\n",
    "        \"validation_accuracy_average_per_epoch\": accuracy_average\n",
    "        })\n",
    "\n",
    "trainer_function(training_dataloader, model, ERROR_FUNC, OPTIMIZER, REPEAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Brain vs Artificial Neural Network\n",
    "\n",
    "- The brain does not learn by implementing a single, global optimization principle within a uniform and undifferentiated neural network.\n",
    "- Rather, biological brains are modular, with distinct but interacting subsystems underpinning key functions such as memory, language, and cognitive control\n",
    "- The primate visual system works differently. Rather than processing all input in parallel, visual attention shifts strategically among locations and objects, centering processing resources and representational coordinates on a series of regions in turn\n",
    "- Continual Learning is an ability to master new tasks without forgetting how to perform prior tasks. Brain does continual Learning easily. Neural Networks can't do that.They do Catastrophic Forgetting\n",
    "- Efficient Learning: ability to rapidly learn about new concepts from only a handful of examples\n",
    "- Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks in more Detail\n",
    "\n",
    "### 7 Steps to Learned Neural Network\n",
    "1. Dataset in Detail\n",
    "2. Neural Network Forward Pass & Dot Product & Activation\n",
    "3. Error Function & Calculation for each Data\n",
    "4. Error Gradient Calculation / Backward Pass\n",
    "5. PARAMETER update in direction of Error Reduction. Model Training Monitoring\n",
    "6. Model Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: MODEL \n",
    "feature_extractor = nn.Sequential(\n",
    "    nn.Conv2d( out_channels = 50, in_channels = 1, kernel_size = (3,3) , padding=\"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2,2), stride = 2),\n",
    "  \n",
    "    nn.Conv2d(out_channels = 100, in_channels = 50, kernel_size = (3,3), padding=\"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2,2), stride = 2),\n",
    "\n",
    ")\n",
    "\n",
    "decision_maker = nn.Sequential(\n",
    "  nn.Linear(out_features = 50, in_features = 100*7*7 ),\n",
    "  nn.Linear(out_features = 10, in_features = 50)\n",
    ")\n",
    "\n",
    "model = nn.Sequential(\n",
    "  feature_extractor,\n",
    "  decision_maker\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest\n",
    "\n",
    "##### Types of Intelligence\n",
    "1. No Intelligence      - \n",
    "1. Narrow Intelligence  - Single Task Intelligence\n",
    "1. General Intelligence - Multiple Tasks Intelligence\n",
    "1. Super Intelligence   - More tasks than possible by Single Human\n",
    "\n",
    "---\n",
    "##### Complexity of Intelligence\n",
    "1. Standing Up & Picking Up a Pen\n",
    "2. Identifying an Object\n",
    "3. Understanding Words\n",
    "---\n",
    "##### Possible Applications via Flexibility\n",
    "1. Robotics\n",
    "2. Visual Factory Hand \n",
    "3. ChatGPT+\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
